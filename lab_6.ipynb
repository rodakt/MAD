{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele analizy danych\n",
    "\n",
    "### 2024/2025, semestr zimowy\n",
    "Tomasz Rodak\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6.1\n",
    "\n",
    "Przewidywania w szeregu czasowym.\n",
    "\n",
    "Pobierz ze [strony](https://repod.icm.edu.pl/dataset.xhtml?persistentId=doi:10.18150/SJHAHR) zbiór `factors_base.xlsx` i wczytaj do ramki danych Pandas. Zbiór ten zawiera wiele zmiennych, nas jednak będą interesować jedynie:\n",
    "\n",
    "* `ln_RVBTC` - logarytm dziennej zmienności kursu BTC. Zmienna celu, którą model powinien przewidywać na podstawie danych historycznych.\n",
    "* `ln_RVBTCd` - logarytm dziennej zmienności kursu BTC z jednodniowym opóźnieniem.\n",
    "* `ln_RVBTCw` - logarytm średniej zmienności kursu BTC z ostatniego tygodnia.\n",
    "* `ln_RVBTCm` - logarytm średniej zmienności kursu BTC z ostatniego miesiąca.\n",
    "* `D_volume` - pierwsza różnica zlogarytmowanego wolumenu kursu BTC.\n",
    "* `D_Google` - pierwsza różnica zlogarytmowanych wskaźników wyszukiwań Google dla BTC.\n",
    "* `ln_Google` - logarytm wskaźników wyszukiwań Google dla BTC.\n",
    "\n",
    "Celem zadania jest zbudowanie modelu regresji liniowej przewidującego `ln_RVBTC` na podstawie pozostałych wymienionych zmiennych. Więcej informacji na temat modelowania zmienności danych finansowych możesz znaleźć [tutaj](https://statmath.wu.ac.at/~hauser/LVs/FinEtricsQF/References/Corsi2009JFinEtrics_LMmodelRealizedVola.pdf).\n",
    "\n",
    "Ramka zawiera 1478 obserwacji. Pierwsze 700 obserwacji przeznacz na zbiór treningowy, kolejne 300 na zbiór walidacyjny, a pozostałe na zbiór testowy.\n",
    "\n",
    "Wytrenuj model regresji liniowej na zbiorze treningowym. Możesz w dowolny sposób przetworzyć dane, usunąć zmienne, dodać nowe, itp., ale staraj się przy tym, aby model był jak najprostszy, a w szczególności aby był łatwy do interpretacji. Model oceniaj za pomocą współczynnika determinacji $R^2$ i błędu średniokwadratowego (MSE) na zbiorze walidacyjnym. Ostateczną ocenę modelu przeprowadź na zbiorze testowym. Wykonaj wspólny wykres wartości przewidywanych i prawdziwych dla zbioru walidacyjnego i testowego. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6.2\n",
    "\n",
    "Niech \n",
    "\n",
    "\\begin{equation*}\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_p X_p + \\varepsilon,\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $\\varepsilon \\sim N(0, \\sigma^2)$, a $X_1, X_2, \\ldots, X_p$ są zmiennymi objaśniającymi. Symbolem $\\mathbf{X}$ oznaczmy macierz obserwacji, w której pierwsza kolumna składa się z jedynek, a pozostałe to kolejne zmienne objaśniające:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "1 & X_{11} & X_{12} & \\ldots & X_{1p} \\\\\n",
    "1 & X_{21} & X_{22} & \\ldots & X_{2p} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & X_{n1} & X_{n2} & \\ldots & X_{np}\n",
    "\\end{bmatrix}.\n",
    "\\end{equation*}\n",
    "\n",
    "Podobnie, niech $\\mathbf{y}$ oznacza wektor obserwacji zmiennej $Y$: $\\mathbf{y} = [Y_1, Y_2, \\ldots, Y_n]^T$.\n",
    "\n",
    "Z metody najmniejszych kwadratów wynika, że współczynniki $\\hat{\\beta}$ w estymatorze $\\hat{y}$ modelu\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_1 + \\hat{\\beta}_2 X_2 + \\ldots + \\hat{\\beta}_p X_p\n",
    "\\end{equation*}\n",
    "\n",
    "wyrażają się wzorem\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}.\n",
    "\\end{equation}\n",
    "\n",
    "Niech\n",
    "\n",
    "\\begin{equation*}\n",
    "Y = \\sin X + \\varepsilon,\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $\\varepsilon \\sim N(0, 0.3)$, a $X \\sim U(0, 2\\pi)$. \n",
    "\n",
    "Wygeneruj tablice `X` i `Y` zawierające 100 obserwacji zgodnie z powyższym modelem. Ponieważ zależność między $X$ i $Y$ jest nieliniowa, więc prosty model, w którym $Y$ jest funkcją liniową $X$ będzie miał wysoki bias. Regresja wielomianowa polega na zastąpieniu kolumny $X$ przez kolumny $X^0, X^1, X^2, \\ldots, X^d$, gdzie $d$ jest stopniem wielomianu. Model ma wówczas postać:\n",
    "\n",
    "\\begin{equation*}\n",
    "Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\ldots + \\beta_d X^d + \\varepsilon.\n",
    "\\end{equation*}\n",
    "\n",
    "Stopień wielomianu $d$ jest hiperparametrem modelu, który powinien zostać odpowiednio dobrany, my jednak na potrzeby tego zadania przyjmijmy, że $d = 5$. Stosując podany wyżej wzór (1) wyznacz współczynniki $\\hat{\\beta}$ dla stopnia $d = 5$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X + \\hat{\\beta}_2 X^2 + \\ldots + \\hat{\\beta}_5 X^5.\n",
    "\\end{equation*}\n",
    "\n",
    "Narysuj wspólny wykres rozrzutu punktów oraz krzywą regresji w 1000 równoodległych punktach z przedziału $[0, 2\\pi]$.\n",
    "\n",
    "Wszystkie obliczenia wykonaj za pomocą biblioteki NumPy, nie korzystaj z gotowych funkcji do regresji wielomianowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6.3\n",
    "\n",
    "Podana niżej funkcja `make_regression_data()` generuje losowe dane do problemu regresji. Opis parametrów:\n",
    "- `n_samples` - liczba obserwacji,\n",
    "- `n_features` - liczba cech,\n",
    "- `n_informative` - liczba cech, od których zależy zmienna objaśniana,\n",
    "- `noise` - poziom szumu dodawanego do zmiennej objaśnianej,\n",
    "- `eigenvalues` - wartości własne macierzy kowariancji cech,\n",
    "- `seed` - ziarno losowości.\n",
    "\n",
    "Zwracane wartości:\n",
    "- `X` - macierz cech o wymiarach `(n_samples, n_features)`,\n",
    "- `y` - wektor zmiennych objaśnianych,\n",
    "- `beta` - wektor współczynników regresji, na pierwszym miejscu znajduje się wyraz wolny.\n",
    "\n",
    "Obserwacje w macierzy `X` są niezależne i mają rozkład wielowymiarowy normalny o zerowej średniej i macierzy kowariancji kontrolowanej przez parametr `eigenvalues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "\n",
    "def make_random_psd_matrix(p, eigenvalues=None):\n",
    "    \"\"\"\n",
    "    Losowa dodatnio określona macierz o wymiarach p x p.\n",
    "    Wartości własne zwracanej macierzy stanowią permutację\n",
    "    pierwiastków z wartości własnych podanych w `eigenvalues`.   \n",
    "    \"\"\"\n",
    "    if eigenvalues is None:\n",
    "        eigenvalues = np.ones(p)\n",
    "    Q = ortho_group.rvs(p)          # losowa macierz ortogonalna\n",
    "    S = np.diag(eigenvalues)        # macierz diagonalna z wartościami własnymi\n",
    "    return Q @ np.sqrt(S) @ Q.T\n",
    "\n",
    "def make_regression_data(\n",
    "    *,\n",
    "    n_samples,\n",
    "    n_features,\n",
    "    n_informative,\n",
    "    noise=1.0,\n",
    "    eigenvalues=None,\n",
    "    seed=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Losowe dane do regresji liniowej.\n",
    "    \n",
    "    Parametry\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Liczba obserwacji.\n",
    "    n_features : int\n",
    "        Liczba cech.\n",
    "    n_informative : int\n",
    "        Liczba cech, od których zależy zmienna objaśniana.\n",
    "    noise : float\n",
    "        Poziom szumu dodawanego do zmiennej objaśnianej.\n",
    "    eigenvalues : list\n",
    "        Wartości własne macierzy kowariancji cech,\n",
    "    seed : int\n",
    "        Ziarno losowości.\n",
    "    \"\"\"\n",
    "    if eigenvalues is not None:\n",
    "        assert len(eigenvalues) == n_features, \"eigenvalues must have length equal to n_features\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    X = np.random.normal(size=(n_samples, n_features))\n",
    "    Sigma = make_random_psd_matrix(n_features, eigenvalues)\n",
    "    X = X @ Sigma\n",
    "    beta = np.zeros(n_features)\n",
    "    beta[:n_informative] = np.exp(np.random.normal(size=n_informative))\n",
    "    beta0 = np.exp(np.random.normal())\n",
    "    beta = beta[np.random.permutation(n_features)]\n",
    "    y = beta0 + X @ beta + np.random.normal(scale=noise, size=n_samples)\n",
    "    return X, y, np.concatenate(([beta0], beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1\n",
    "\n",
    "Za pomocą funkcji `make_regression_data()` wygeneruj dane do problemu regresji liniowej w dwuwymiarowej przestrzeni cech dla różnych wartości parametru `eigenvalues`. Wyjaśnij, jak parametr ten wpływa na postać macierzy cech `X`. Wykonaj przykładowy wykres rozproszenia danych wraz z prostą regresji jednej z cech względem drugiej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2\n",
    "\n",
    "Za pomocą funkcji `make_regression_data()` stwórz ramkę danych o kolumnach `X1`, ..., `X10` oraz `y` dla parametrów:\n",
    "- `n_samples=1000`,\n",
    "- `n_features=10`,\n",
    "- `n_informative=5`,\n",
    "- `noise=1.0`,\n",
    "- `seed=<Twój numer albumu>`.\n",
    "\n",
    "Parametr `eigenvalues` zdefiniuj za pomocą wzoru:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{eigenvalues} = \\exp\\left(-\\left(\\frac{i}{\\text{effective rank}}\\right)^2\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $i=0,1,2,\\ldots,(\\text{n features})-1$. Tak zdefiniowany parametr `eigenvalues` jest ciągiem malejącym, zaczynającym się od wartości $1$ i szybko opadającym do zera za wartością `effective_rank`. Powoduje to, że $p-(\\text{effective rank})$ wartości własnych macierzy kowariancji cech jest bliskich zeru a macierz $X$ jest bliska macierzy o rzędzie $\\text{effective rank}$. Pomysł ten, w nieco innej sytuacji, implementuje funkcja [`sklearn.datasets.make_low_rank_matrix()`](https://github.com/scikit-learn/scikit-learn/blob/6e9039160/sklearn/datasets/_samples_generator.py#L1357).\n",
    "\n",
    "Jako wartość parametru `effective_rank` przyjmij $3$. \n",
    "\n",
    "Stwórz model regresji liniowej zmiennej `y` względem wszystkich zmiennych w `X`. Odpowiedz na pytania:\n",
    "1. Czy wszystkie zmienne są istotne statystycznie?\n",
    "2. Czy model jest istotny jako całość?\n",
    "3. Zapisz model w postaci równania regresji. Czy model odtwarza prawdziwe wartości współczynników? Jeśli nie, to dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.3\n",
    "\n",
    "W tym punkcie wykorzystaj dane z punktu 1.2. Przeprowadź selekcję zmiennych stosując następującą procedurę:\n",
    "1. Sprawdź, która cecha ma najwyższy współczynnik VIF (variance inflation factor). Usuń ją, jeśli współczynnik ten jest większy od 5.\n",
    "2. Powtarzaj krok 1, aż żaden współczynnik VIF nie będzie większy od 5.\n",
    "\n",
    "Stwórz model regresji liniowej zmiennej `y` względem wyselekcjonowanych zmiennych. Porównaj wyniki z modelem z punktu 1.2, odpowiedz na analogiczne pytania. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.4\n",
    "\n",
    "Napisz funkcję `low_vif_variables(df, threshold=5, skip=[])` automatyzującą procedurę selekcji zmiennych z punktu 1.3.\n",
    "\n",
    "Parametry:\n",
    "- `df` - ramka danych,\n",
    "- `threshold` - wartość progowa współczynnika VIF,\n",
    "- `skip` - lista zmiennych, które mają być pominięte w procesie selekcji (np. kolumna zmiennych objaśnianych).\n",
    "\n",
    "Funkcja w iteracyjny sposób usuwa zmienne z maksymalnym współczynnikiem VIF o ile jest on większy niż `threshold`.\n",
    "Proces powtarza się, aż żadna zmienna nie będzie miała współczynnika VIF większego niż `threshold`. Funkcja zwraca listę pozostałych zmiennych.\n",
    "\n",
    "Zastosuj funkcję `low_vif_variables()` do danych z punktu 1.2. Sprawdź, czy wyniki są zgodne z wynikami z punktu 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
