{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele analizy danych\n",
    "\n",
    "### 2024/2025, semestr zimowy\n",
    "Tomasz Rodak\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna\n",
    "\n",
    "Celem tego arkusza jest zapoznanie się z biblioteką [Optuna](https://optuna.org/). Jest to biblioteka automatyzująca proces optymalizacji funkcji o wartościach rzeczywistych (czyli proces znajdowania minimum lub maksimum lokalnego funkcji). W praktyce Optuna jest typowo stosowana do optymalizacji hiperparametrów modeli uczenia maszynowego.\n",
    "\n",
    "Podstawowe obiekty definiowane w Optuna to:\n",
    "- **`Study`** - obiekt reprezentujący proces optymalizacji funkcji celu, składa się na niego wiele prób.\n",
    "- **`Trial`** - próba, obiekt reprezentujący pojedyńcze obliczenie wartości funkcji celu.\n",
    "\n",
    "### Przykład\n",
    "<!-- y = np.exp(np.sin(x**2)) + x**2/5 - x\n",
    " -->\n",
    "Wyznaczymy minimum funkcji lokalne funkcji \n",
    "$$\n",
    "f(x) = \\exp\\sin x^2 + \\frac{x^2}{5} - x\n",
    "$$\n",
    "na przedziale $x \\in [-5, 5]$.\n",
    "\n",
    "Wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "y = np.exp(np.sin(x**2)) + x**2/5 - x\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(x, y)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optymalizacja w Optunie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "a, b = -5, 5\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', a, b)\n",
    "    return np.exp(np.sin(x**2)) + x**2/5 - x\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja `objective()` gra rolę funkcji celu, której wartość ma być (w tym przypadku) minimalizowana. Funkcja ta przyjmuje jeden argument `trial`, który jest obiektem reprezentującym pojedyńczą próbę optymalizacyjną. Wiersz\n",
    "\n",
    "```python\n",
    "x = trial.suggest_float('x', -5, 5)\n",
    "```\n",
    "\n",
    "zmusza Optunę do wskazania zmiennoprzecinkowego kandydata zmiennej `x` z przedziału $[-5, 5]$. Wskazanie to odbywa się w sposób adaptacyjny, tzn. Optuna kieruje się w sugestiach wartościami, które zostały już sprawdzone w poprzednich próbach. Wartość zmiennej `x` jest następnie przekazywana do faktycznej funkcji celu `f(x)`. Ostatecznie `objective()` zwraca wartość funkcji celu dla danego kandydata, która jest zapisywana w obiekcie `trial` i służy do oceny jakości kandydata. Ponieważ naszym celem jest minimalizacja, więc kandydat z mniejszą wartością funkcji celu jest lepszy.\n",
    "\n",
    "Wywołanie\n",
    "    \n",
    "```python\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "```\n",
    "\n",
    "rozpoczyna proces optymalizacji. Argument `n_trials` określa liczbę prób, które mają być wykonane. Argument `direction` określa kierunek optymalizacji, w tym przypadku minimalizację. Po zakończeniu optymalizacji obiekt `study` zawiera wyniki optymalizacji, w tym najlepsze wartości zmiennych.\n",
    "\n",
    "Wyniki:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "best_x = best_trial.params['x']\n",
    "best_y = best_trial.value\n",
    "print(f'Best x: {best_x:.3f}, Best y: {best_y:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie próby na wykresie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(x, y)\n",
    "for t in study.trials:\n",
    "    ax.scatter(t.params['x'], t.value, color='red')\n",
    "ax.scatter(best_x, best_y, color='green')\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampler\n",
    "\n",
    "Sposób w jaki Optuna wybiera kandydatów do oceny zależy od użytego samplera. Domyślnie Optuna stosuje algorytm optymalizacji bayesowskiej z samplerem `TPESampler` (Tree-structured Parzen Estimator). Możliwe jest również użycie innych samplerów, np. `RandomSampler` czy `GridSampler`. Sampler można ustawić w wywołaniu `create_study()`.\n",
    "\n",
    "Oto przykład użycia `GridSampler`. W tym przypadku Optuna będzie wybierać kandydatów z siatki przekazanej w argumencie `search_space` samplera. Warto zauważyć, że w przypadku `GridSampler` optymalizacja bayesowska nie ma sensu, ponieważ sprawdzane są wszystkie możliwe wartości. Aby przejść przez wszystkie punkty siatki, `n_trials` musi być ustawione na liczbę punktów w siatce. Ewentualnie można ustawić `n_trials` na `None` - wtedy optymalizacja będzie trwała dopóki nie zostaną sprawdzone wszystkie punkty siatki - lub na wartość mniejszą niż liczba punktów w siatce - wtedy optymalizacja zakończy się po sprawdzeniu `n_trials` punktów, ale może być wznawiana w przyszłości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'x': np.linspace(a, b, 10)\n",
    "}\n",
    "study = optuna.create_study(sampler=optuna.samplers.GridSampler(search_space), direction='minimize')\n",
    "study.optimize(objective, n_trials=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "best_x = best_trial.params['x']\n",
    "best_y = best_trial.value\n",
    "print(f'Best x: {best_x:.3f}, Best y: {best_y:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(x, y)\n",
    "for t in study.trials:\n",
    "    ax.scatter(t.params['x'], t.value, color='black')\n",
    "ax.scatter(best_x, best_y, color='green')\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizacja hiperparametrów modelu\n",
    "\n",
    "Załóżmy, że mamy zbiór obserwacji `X` i `y` wygenerowanych z modelu\n",
    "\n",
    "\\begin{align*}\n",
    "X &\\sim \\text{Uniform}(0, 10) \\\\\n",
    "Y &\\sim \\sin(X) + \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, 0.2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "a, b = 0, 10\n",
    "X = np.random.uniform(a, b, N)\n",
    "y = np.sin(X) + np.random.normal(0, 0.2, N)\n",
    "xx = np.linspace(a, b, 1000)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.scatter(X, y)\n",
    "ax.plot(xx, np.sin(xx), color='red', label='$E[Y|X=x]$')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naszym celem jest zbudowanie modelu regresji wielomianowej z regularyzacją L2. Model ma wówczas postać\n",
    "\n",
    "$$\n",
    "y = \\sum_{i=0}^d w_i x^i\n",
    "$$\n",
    "\n",
    "gdzie $d$ to stopień wielomianu, a $w_i$ to współczynniki regresji. Regularyzacja L2 polega na dodaniu do funkcji celu kary za duże wartości współczynników:\n",
    "\n",
    "$$\n",
    "\\text{RSS} + \\lambda \\sum_{i=0}^d w_i^2\n",
    "$$\n",
    "\n",
    "gdzie $\\text{RSS}$ to suma kwadratów reszt, a $\\lambda$ to współczynnik regularyzacji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=5)),\n",
    "    ('ridge', Ridge(alpha=1e-3))\n",
    "])\n",
    "model.fit(X[:, None], y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.scatter(X, y)\n",
    "ax.plot(xx, np.sin(xx), color='red', label='$E[Y|X=x]$')\n",
    "ax.plot(xx, model.predict(xx[:, None]), color='green', label='Model')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametrami modelu są $d$ i $\\lambda$. Naszym celem jest znalezienie takich wartości hiperparametrów, które minimalizują błąd testowy modelu. Przestrzeń hiperparametrów przeszukamy za pomocą Optuny, jak jednak zaimplementować funkcję celu, która powinna zwracać błąd testowy? Błąd testowy obliczamy na tej części danych, które nie były użyta do uczenia modelu. Jedna z prostszych strategii to podzielenie danych na zbiór treningowy i walidacyjny. Część treningową użyjemy do uczenia modelu, a część walidacyjną do obliczenia błędu testowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0, 100, log=False)\n",
    "    degree = trial.suggest_int('degree', 1, 20)\n",
    "    model = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree)),\n",
    "        ('linear', Ridge(alpha=alpha))\n",
    "    ])\n",
    "    # test stabilności numerycznej\n",
    "    XX = model.named_steps['poly'].fit_transform(X_train[:, None])\n",
    "    Z = XX.T @ XX + alpha * np.eye(XX.shape[1])\n",
    "    singular_values = np.linalg.svd(Z, compute_uv=False)\n",
    "    rcond = np.min(singular_values) / np.max(singular_values)\n",
    "    if rcond < 1e-15:\n",
    "        return np.inf\n",
    "    else:\n",
    "        model.fit(X_train[:, None], y_train)\n",
    "        y_pred = model.predict(X_val[:, None])\n",
    "        test_loss = np.mean((y_val - y_pred)**2)\n",
    "        return test_loss\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "best_alpha = best_trial.params['alpha']\n",
    "best_degree = best_trial.params['degree']\n",
    "best_loss = best_trial.value\n",
    "print(f'Best alpha: {best_alpha:.3f}, Best degree: {best_degree}, Best loss: {best_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=best_degree)),\n",
    "    ('linear', Ridge(alpha=best_alpha))\n",
    "])\n",
    "model.fit(X[:, None], y)\n",
    "yy = model.predict(xx[:, None])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.scatter(X, y)\n",
    "ax.plot(xx, np.sin(xx), color='red', label='$E[Y|X=x]$')\n",
    "ax.plot(xx, yy, color='green', label='Model')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the optimization process in dashboard\n",
    "import optuna.visualization as vis\n",
    "vis.plot_optimization_history(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
