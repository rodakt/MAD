{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele analizy danych\n",
    "\n",
    "Tomasz Rodak\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7.1\n",
    "\n",
    "Mamy model, który generuje dane w dwóch krokach:\n",
    "\n",
    "1. Losujemy wartość $y\\in\\{0,1\\}$ z prawdopodobieństwami $P(Y=1)=p$ oraz $P(Y=0)=1-p$.\n",
    "2. Warunkowo względem $Y=y$ losujemy wartość $x\\in\\mathbb{R}$ z rozkładu normalnego $N(\\mu_y,\\sigma^2)$.\n",
    "\n",
    "Niech $(X,Y)$ będzie parą zmiennych losowych o wartościach w $\\mathbb{R}\\times\\{0,1\\}$. \n",
    "Para ta ma pewien rozkład łączny, który można zapisać jako odzwierciedlenie opisanego wyżej modelu:\n",
    "\n",
    "\\begin{equation*}\n",
    "g(x,y) = g_Y(y) g_{X|Y}(x\\mid y),\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie\n",
    "\n",
    "* $g_Y(1)=p$, $g_Y(0)=1-p$,\n",
    "* $g_{X|Y}(x\\mid y)$ jest gęstością rozkładu normalnego $N(\\mu_y,\\sigma^2)$.\n",
    "\n",
    "---\n",
    "\n",
    "**Przypis.** Formalnie funkcja $g(x,y)$ jest gęstością rozkładu łącznego $(X,Y)$ względem miary produktowej $\\lambda\\otimes\\nu_{\\text{count}}$, gdzie $\\lambda$ jest miarą Lebesgue’a na $\\mathbb{R}$, a $\\nu_{\\text{count}}$ miarą zliczającą na $\\{0,1\\}$. Całka względem tej miary ma postać:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\int_{\\mathbb{R}\\times\\{0,1\\}} f(x,y)d(\\lambda\\otimes\\nu_{\\text{count}})(x,y)=\n",
    "\\int_{\\mathbb{R}} f(x,0)dx + \\int_{\\mathbb{R}} f(x,1)dx.\n",
    "\\end{equation*}\n",
    "\n",
    "Fakt, że $g(x,y)$ jest gęstością rozkładu łącznego $(X,Y)$ względem tej miary, oznacza, że całki względem miary probabilistycznej $P_{(X,Y)}$ można wyrazić jako całki względem miary produktowej $\\lambda\\otimes\\nu_{\\text{count}}$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\int_{\\Omega} f\\big((X(\\omega),Y(\\omega))\\big)dP_{(X,Y)}(\\omega) = \\int_{\\mathbb{R}\\times\\{0,1\\}} f(x,y) g(x,y)d(\\lambda\\otimes\\nu_{\\text{count}})(x,y).\n",
    "\\end{equation*}\n",
    "\n",
    "W szczególności:\n",
    "\n",
    "\\begin{equation*}\n",
    "E\\big[h(X,Y)\\big] = \\int_{\\mathbb{R}\\times\\{0,1\\}} h(x,y) g(x,y)d(\\lambda\\otimes\\nu_{\\text{count}})(x,y).\n",
    "\\end{equation*}\n",
    "\n",
    "oraz\n",
    "\n",
    "\\begin{equation*}\n",
    "P\\big((X,Y)\\in B\\big) = \\int_{B} g(x,y)d(\\lambda\\otimes\\nu_{\\text{count}})(x,y),\n",
    "\\end{equation*}\n",
    "\n",
    "dla dowolnego mierzalnego zbioru $B\\subseteq \\mathbb{R}\\times\\{0,1\\}$.\n",
    "\n",
    "---\n",
    "\n",
    "Ponieważ rozkład łączny $(X,Y)$ jest znany, więc możemy wyznaczyć rozkład warunkowy $Y$ względem $X$, zbudować klasyfikator Bayesa, obliczyć oczekiwany błąd predykcji oraz porównać go z wynikami uzyskanymi przy użyciu praktycznych metod klasyfikacji, takich jak metoda k-najbliższych sąsiadów czy regresja logistyczna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rozkład warunkowy $Y$ względem $X$\n",
    "\n",
    "Z twierdzenia Bayesa mamy:\n",
    "\n",
    "\\begin{equation*}\n",
    "g_{Y|X}(y\\mid x) = \\frac{g(x, y)}{g_X(x)},\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $g_X(x)$ jest brzegową funkcją gęstości zmiennej losowej $X$. Zatem:\n",
    "\n",
    "\\begin{equation*}\n",
    "g_X(x) = \\sum_{y\\in\\{0, 1\\}} g(x, y) = g(x, 0) + g(x, 1) = (1-p) N(x\\mid\\mu_0, \\sigma^2) + p N(x\\mid\\mu_1, \\sigma^2).\n",
    "\\end{equation*}\n",
    "\n",
    "Wobec tego:\n",
    "\n",
    "\\begin{equation*}\n",
    "g_{Y|X}(y\\mid x) = \\frac{g_Y(y) g_{X|Y}(x\\mid y)}{(1-p) N(x\\mid\\mu_0, \\sigma^2) + p N(x\\mid\\mu_1, \\sigma^2)}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Klasyfikator Bayesa\n",
    "\n",
    "Klasyfikator Bayesa przypisuje obserwację $x$ do klasy $1$, jeśli:\n",
    "\n",
    "\\begin{equation*}\n",
    "g_{Y|X}(1\\mid x) > g_{Y|X}(0\\mid x),\n",
    "\\end{equation*}\n",
    "\n",
    "w przeciwnym razie przypisuje ją do klasy $0$. Zatem $x$ zostanie przypisane do klasy $1$, jeśli:\n",
    "\n",
    "\\begin{equation*}\n",
    "g_Y(1) g_{X|Y}(x\\mid 1) > g_Y(0) g_{X|Y}(x\\mid 0),\n",
    "\\end{equation*}\n",
    "\n",
    "czyli:\n",
    "\n",
    "\\begin{equation*}\n",
    "p N(x\\mid\\mu_1, \\sigma^2) > (1-p) N(x\\mid\\mu_0, \\sigma^2).\n",
    "\\end{equation*}\n",
    "\n",
    "Podstawiając wzór na gęstość rozkładu normalnego i logarytmując obie strony nierówności, otrzymujemy postać równoważną:\n",
    "\n",
    "\\begin{equation*}\n",
    "2x(\\mu_1 - \\mu_0) > \\mu_1^2 - \\mu_0^2 - 2\\sigma^2 \\log\\left(\\frac{p}{1-p}\\right).\n",
    "\\end{equation*}\n",
    "\n",
    "Zatem, oznaczając klasyfikator Bayesa przez $f^*$, mamy:\n",
    "\n",
    "\\begin{equation*}\n",
    "f^*(x) = \\begin{cases}\n",
    "1 & \\text{gdy } 2x(\\mu_1 - \\mu_0) > \\mu_1^2 - \\mu_0^2 - 2\\sigma^2 \\log\\left(\\frac{p}{1-p}\\right), \\\\\n",
    "0 & \\text{w przeciwnym razie}.\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "Widzimy, że $f^*$ jest funkcją stałą na przedziałach $(-\\infty, t)$ oraz $[t, \\infty)$, gdzie:\n",
    "\n",
    "\\begin{equation}\n",
    "t = \\frac{\\mu_1+\\mu_0}{2} - \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\log\\left(\\frac{p}{1-p}\\right).\\tag{wartość progowa}\n",
    "\\end{equation}\n",
    "\n",
    "Od relacji między $\\mu_1$ a $\\mu_0$ zależy, czy klasyfikator przypisuje do klasy $1$ wartości większe czy mniejsze od progu $t$.\n",
    "\n",
    "**Zauważmy, że konstrukcja klasyfikatora Bayesa nie wymaga znajomości rozkładu brzegowego $g_X(x)$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Błąd Bayesa\n",
    "\n",
    "Błąd Bayesa to oczekiwane prawdopodobieństwo błędnej klasyfikacji przy użyciu klasyfikatora Bayesa: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\operatorname{EPE}(f^*) = E(I(f^*(X) \\neq Y)).\n",
    "\\end{equation*}\n",
    "\n",
    "Z definicji wartości oczekiwanej względem rozkładu łącznego $(X,Y)$ otrzymujemy (zob. przypis):\n",
    "\n",
    "\\begin{equation*}\n",
    "\\operatorname{EPE}(f^*) = \\int_{\\mathbb{R}\\times\\{0, 1\\}} I(f^*(x) \\neq y) g(x, y) d(\\lambda \\otimes \\nu_{\\text{count}})(x,y).\n",
    "\\end{equation*}\n",
    "\n",
    "Korzystając z postaci rozkładu łącznego $g(x,y)= g_Y(y) g_{X|Y}(x\\mid y)$ przekształcamy powyższą całkę:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\operatorname{EPE}(f^*) &= \\int_\\mathbb{R}\\left(I(f^*(x) \\neq 0) (1-p) N(x\\mid\\mu_0, \\sigma^2) + I(f^*(x) \\neq 1) p N(x\\mid\\mu_1, \\sigma^2)\\right) \\lambda(dx)\\\\\n",
    "&= \\int_{\\{x: f^*(x) = 1\\}} (1-p) N(x\\mid\\mu_0, \\sigma^2) \\lambda(dx) + \\int_{\\{x: f^*(x) = 0\\}} p N(x\\mid\\mu_1, \\sigma^2) \\lambda(dx).\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Zbiory $\\{x: f^*(x) = 1\\}$ oraz $\\{x: f^*(x) = 0\\}$ są przedziałami określonymi przez wartość progową $t$ z równania (wartość progowa). Załóżmy, że $\\mu_1 > \\mu_0$. Wówczas:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\operatorname{EPE}(f^*) &= \\int_{-\\infty}^{t} (1-p) N(x\\mid\\mu_0, \\sigma^2) \\lambda(dx) + \\int_{t}^{\\infty} p N(x\\mid\\mu_1, \\sigma^2) \\lambda(dx) \\\\\n",
    "&= (1-p) \\Phi(t\\mid\\mu_0, \\sigma^2) + p \\left(1 - \\Phi(t\\mid\\mu_1, \\sigma^2)\\right) \\\\\n",
    "&= (1-p) \\Phi\\left(\\frac{t - \\mu_0}{\\sigma}\\right) + p \\left(1 - \\Phi\\left(\\frac{t - \\mu_1}{\\sigma}\\right)\\right),\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "gdzie $\\Phi(\\cdot\\mid\\mu, \\sigma^2)$ jest dystrybuantą rozkładu normalnego o średniej $\\mu$ i wariancji $\\sigma^2$. W przypadku, gdy $\\mu_1 < \\mu_0$, rozwiązanie jest analogiczne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Część praktyczna\n",
    "\n",
    "Ustal wartości parametrów modelu: $p$, $\\mu_0$, $\\mu_1$, $\\sigma$ oraz liczbę obserwacji treningowych i testowych. Wygeneruj dane treningowe i testowe zgodnie z powyższym modelem. Następnie:\n",
    "1. Oblicz błąd Bayesa dla ustalonych parametrów modelu - błąd teoretyczny najlepszego klasyfikatora $f^*$.\n",
    "2. Wyznacz błąd klasyfikatora Bayesa na danych testowych - błąd empiryczny najlepszego klasyfikatora $f^*$.\n",
    "3. Wyznacz błąd klasyfikatora $k$-najbliższych sąsiadów na danych testowych dla różnych wartości $k$. Uczenie modelu przeprowadź na danych treningowych.\n",
    "4. Wyznacz błąd regresji logistycznej na danych testowych. Podobnie jak wyżej, uczenie modelu przeprowadź na danych treningowych.\n",
    "5. Jeśli znasz inne metody klasyfikacji, możesz również je zastosować.\n",
    "\n",
    "Eksperymentuj z różnymi wartościami parametrów. Skomentuj otrzymane wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7.2\n",
    "\n",
    "Uzupełnij analizę z zadania 7.1 o brakujący przypadek $\\mu_1 = \\mu_0$. W szczególności:\n",
    "* Jaki jest klasyfikator Bayesa, gdy $\\mu_1 = \\mu_0$?\n",
    "* Jaki jest błąd Bayesa w tym przypadku?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 7.3\n",
    "\n",
    "W zadaniu 7.1 założyliśmy, że wariancje rozkładów warunkowych są równe. Fakt ten spowodował, że klasyfikator Bayesa był funkcją progową z jednym progiem wyznaczonym z równania liniowego (prześledź rachunki i zwróć uwagę na to jak składnik kwadratowy względem $x$ się skraca). Przeprowadź analizę analogiczną do tej z zadania 7.1, ale dla przypadku, gdy wariancje rozkładów warunkowych są różne, tzn.:\n",
    "* dla $y=0$: $X\\mid Y=0 \\sim N(\\mu_0, \\sigma_0^2)$,\n",
    "* dla $y=1$: $X\\mid Y=1 \\sim N(\\mu_1, \\sigma_1^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
